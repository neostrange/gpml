{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/gpml_spacy3/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "def dep_pattern(doc):\n",
    "  for i in range(len(doc)-1):\n",
    "    if doc[i].dep_ == 'nsubj' and doc[i+1].dep_ == 'aux' and  doc[i+2].dep_ == 'ROOT':\n",
    "      for tok in doc[i+2].children:\n",
    "        if tok.dep_ == 'dobj':\n",
    "          return True\n",
    "  return False\n",
    "doc = nlp(u'We can overtake them.')\n",
    "if dep_pattern(doc):\n",
    "  print('Found')\n",
    "else:\n",
    "  print('Not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span:  We can overtake\n",
      "The positions in the doc are:  0 - 3\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"DEP\": \"nsubj\"}, {\"DEP\": \"aux\"}, {\"DEP\": \"ROOT\"}]\n",
    "matcher.add(\"NsubjAuxRoot\", [pattern])\n",
    "doc = nlp(u\"We can overtake them.\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "  span = doc[start:end]\n",
    "  print(\"Span: \", span.text)\n",
    "  print(\"The positions in the doc are: \", start, \"-\", end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found\n"
     ]
    }
   ],
   "source": [
    "# multi-pattern i.e., patterns based on both POS + DEP\n",
    "def dep_pattern(doc):\n",
    "  for i in range(len(doc)-1):\n",
    "    if doc[i].dep_ == 'nsubj' and doc[i+1].dep_ == 'aux' and  doc[i+2].dep_ == 'ROOT':\n",
    "      for tok in doc[i+2].children:\n",
    "        if tok.dep_ == 'dobj':\n",
    "          return True\n",
    "  return False\n",
    "def pos_pattern(doc):\n",
    "  for token in doc:\n",
    "    if token.dep_ == 'nsubj' and token.tag_ != 'PRP':\n",
    "      return False\n",
    "    if token.dep_ == 'aux' and token.tag_ != 'MD':\n",
    "      return False\n",
    "    if token.dep_ == 'ROOT' and token.tag_ != 'VB':\n",
    "      return False\n",
    "    if token.dep_ == 'dobj' and token.tag_ != 'PRP':\n",
    "      return False\n",
    "  return True\n",
    "#Testing code\n",
    "doc = nlp(u'We can overtake them.')\n",
    "if dep_pattern(doc) and pos_pattern(doc):\n",
    "  print('Found')\n",
    "else:\n",
    "  print('Not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Self-driving cars, insurance liability, manufacturers]\n",
      "Self-driving cars cars nsubj shift\n",
      "insurance liability liability dobj shift\n",
      "manufacturers manufacturers pobj toward\n"
     ]
    }
   ],
   "source": [
    "# extracting noun chunks, their text, their dep, and their head word\n",
    "doc = nlp(\"Self-driving cars shift insurance liability toward manufacturers.\")\n",
    "\n",
    "print(list(doc.noun_chunks))\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Myriam nsubj saw VERB []\n",
      "saw ROOT saw VERB [Myriam, Clement, with, .]\n",
      "Clement dobj saw VERB []\n",
      "with prep saw VERB [telescope]\n",
      "a det telescope NOUN []\n",
      "telescope pobj with ADP [a]\n",
      ". punct saw VERB []\n"
     ]
    }
   ],
   "source": [
    "# token meta-data along with the children of each node\n",
    "doc = nlp(\"Myriam saw Clement with a telescope.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_, [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{shift}\n"
     ]
    }
   ],
   "source": [
    "# how to find a root verb(head) of a sentence using nsubj dependency\n",
    "\n",
    "from spacy.symbols import nsubj, VERB \n",
    "doc = nlp(\"Self-driving cars shift insurance liability toward manufacturers.\")\n",
    "verbs = set()\n",
    "for possible_subject in doc:\n",
    "    if possible_subject.dep == nsubj and possible_subject.head.pos == VERB: \n",
    "        verbs.add(possible_subject.head)\n",
    "\n",
    "print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self npadvmod 0 0 ['driving', 'cars', 'shift']\n",
      "- punct 0 0 ['driving', 'cars', 'shift']\n",
      "driving amod 2 0 ['cars', 'shift']\n",
      "cars nsubj 1 0 ['shift']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Self-driving cars shift insurance liability toward manufacturers.')\n",
    "root = [token for token in doc if token.head == token][0] \n",
    "subject = list(root.lefts)[0] \n",
    "for descendant in subject.subtree:\n",
    "    assert subject is descendant or subject.is_ancestor(descendant) \n",
    "    print(descendant.text, descendant.dep_, descendant.n_lefts, descendant.n_rights, \n",
    "    [ancestor.text for ancestor in descendant.ancestors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explore\n",
      "differences\n",
      "[differences, in, words, that, represent, people, ,, places, and, things, (, nouns, ,, including, pronouns, ), ,, happenings, and, states, (, verbs, ), ,, qualities, (, adjectives, ), and, details, such, as, when, ,, where, and, how, (, adverbs, )]\n",
      "direct object rights:  [in]\n",
      "context:  ['in words']\n"
     ]
    }
   ],
   "source": [
    "#doc = nlp(\"Measure and compare the lengths and capacities of pairs of objects using uniform informal units\")\n",
    "doc = nlp(\"Explore differences in words that represent people, places and things (nouns, including pronouns), happenings and states (verbs), qualities (adjectives) and details such as when, where and how (adverbs)\")\n",
    "#doc = nlp('Explore the different contribution of words and images to meaning in stories and informative texts.')\n",
    "root = [token for token in doc if token.head == token][0] \n",
    "\n",
    "print(root.text)\n",
    "\n",
    "directObject = list(root.rights)[0]\n",
    "\n",
    "print(directObject.text)\n",
    "\n",
    "print(list(directObject.subtree))\n",
    "\n",
    "#for descendant in directObject.subtree:\n",
    " #   print(list(descendant.rights))\n",
    "\n",
    "context = []\n",
    "\n",
    "print('direct object rights: ', list(directObject.rights))\n",
    "\n",
    "for node in directObject.rights:\n",
    "    children = node.children\n",
    "    for child in children:\n",
    "        if child.dep_ == 'pobj':\n",
    "            context.append(node.text +\" \" + child.text)\n",
    "            if child.conjuncts:\n",
    "                for conjunct in child.conjuncts:\n",
    "                  context.append(node.text +\" \" + conjunct.text)  \n",
    "\n",
    "print(\"context: \", context)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac311bd4cf06ac5ef38658be0e3c84de8924258d4d0dd52ea8382e20482ad5df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
